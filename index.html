<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>MBTIxSpotify</title>
    <link rel="stylesheet" type="text/css" href="css/global.css">
    <!-- Include any necessary stylesheets or meta tags -->
    <!-- Load d3.js -->
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Exo+2:wght@500&family=Playfair+Display:ital@1&family=Playfair:ital,opsz,wght@0,5..1200,400;1,5..1200,400;1,5..1200,500&display=swap" rel="stylesheet">
</head>
<body>
  <!-- <h4>Steph Wu</h4> -->
  <h1>Spotify & MBTI Playlists</h1>
  <div id="headblurb">
  <!-- <h3 style="width: 200px;">The dataset I chose contains information on 4,081 Spotify playlists, each labeled with the Myers Briggs Type Indicator (MBTI) personality type and function pair. This visualization attempts to better understand the relationship between personality types and musical preferences.</h3> -->
</div>


  <div class="container">
    <div class="chart-container">
        <div id="my_dataviz"></div>
        <div class="introduction">

      </div>
    </div>
    <!-- <div class="text-info">
      <h2>16 Personalities: An Introduction</h2>
      <p>Katherine Briggs and Isabel Briggs Myers developed the Myers-Briggs Type Indicator (MBTI) by drawing inspiration from Carl Jung's Psychological Types. After two decades of research, they finalized the assessment, categorizing individuals into 16 distinct personalities based on four key designations: Extraversion (E) or Introversion (I), Sensing (S) or Intuition (N), Thinking (T) or Feeling (F), and Judging (J) or Perceiving (P).<br>

<br>The MBTI comprises 93 "forced choice" questions and aims to help individuals understand their preferences in perceiving information, making decisions, and interacting with the world. It's not about ranking personalities but exploring individual traits, strengths, weaknesses, career inclinations, and relationships. The test isn't meant to diagnose dysfunction but encourages self-exploration and understanding.<br>

<br>The four personality designations define how individuals respond to the world: Extraversion (outward focus vs. inner world orientation), Sensing (relying on facts vs. interpreting impressions), Thinking (fact-based decisions vs. emotion-based decisions), and Judging (structured vs. open-minded). Everyone has aspects of each, but most have a preference for one over the other in each designation.</p>
    </div> -->
</div>


    <div id="chartContainer">
      <div class="text-info">
        


    </div>
        <div id="buttonsContainer">
          <!-- Buttons will be appended here -->
        </div>
        
        <div id="chart2">
          <!-- <div class="text-info-chart2">
            <h2>Spotify Audio Features and MBTIs</h2>
            <p>
            <strong>Danceability:</strong> Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.<br><br>
            <strong>Energy:</strong> Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.<br><br>
            <strong>Acousticness:</strong> A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.<br><br>
            <strong>Speechiness:</strong> Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.<br><br>
            <strong>Valence:</strong> A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).<br><br>
            <strong>Instrumentalness:</strong> Predicts whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly "vocal." The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content.<br><br>
          </p>
          </div> -->
        </div>
        
      </div>



      <div class="middlechart">

        <div class="middlechartcontainer">
          
     
          <div id="chart3"></div>
          
        </div>
        <!-- <div class="text-info-chart3">
          <h2>Key Counts and Their Associated Emotions</h2>
          <p><strong>A MINOR:</strong> Tender, Plaintive, Pious<br><br>
            <strong>A MAJOR:</strong> Joyful, Pastoral, Declaration of Love<br><br>
            <strong>C MINOR:</strong>	Innocently Sad, Love-Sick<br><br>
            <strong>C MAJOR:</strong> Innocently Happy<br><br>
            <strong>D MINOR:</strong> Serious, Pious, Ruminating<br><br>
            <strong>D MAJOR:</strong> Triumphant, Victorious War-Cries<br><br>
            <strong>E MINOR:</strong> Effeminate, Amorous, Restless<br><br>
            <strong>E MAJOR:</strong> Quarrelsome, Boisterous, Incomplete Pleasure<br><br>
          </p>
        </div> -->

  </div>
</div>

      


    <!-- Include your JavaScript file -->
    <script type="module" async src="./js/app1.js"></script>
    <script type="module" async src="./js/app2.js"></script>
    <script type="module" async src="./js/app3.js"></script>
    
</body>
</html>

<!-- const colorScale = d3.scaleLinear().domain([0, 1]).range(['red', 'blue'])
window.colorScale = colorScale;

const shape = d3
  .select(body)
  .append('div')
  .style('border-radius', '999px') -->